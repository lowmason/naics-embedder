â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    GPU MEMORY OPTIMIZATION - QUICK REFERENCE                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€ COMMANDS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                                â”‚
â”‚  Check Current Config:                                                         â”‚
â”‚    uv run python scripts/show_current_config.py                               â”‚
â”‚                                                                                â”‚
â”‚  Get Recommendations:                                                          â”‚
â”‚    uv run python scripts/optimize_gpu_config.py --auto                        â”‚
â”‚                                                                                â”‚
â”‚  Apply Settings:                                                               â”‚
â”‚    uv run python scripts/optimize_gpu_config.py --auto --apply                â”‚
â”‚                                                                                â”‚
â”‚  Profile GPU Memory:                                                           â”‚
â”‚    uv run python scripts/optimize_gpu_config.py --auto --profile              â”‚
â”‚                                                                                â”‚
â”‚  Monitor Training:                                                             â”‚
â”‚    watch -n 1 nvidia-smi                                                       â”‚
â”‚                                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ COMMON GPU CONFIGURATIONS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                                â”‚
â”‚  GPU Model      â”‚ Memory â”‚ batch_size â”‚ accumulate â”‚ Effective â”‚ Utilization  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  RTX 6000      â”‚  24 GB â”‚     45     â”‚      5     â”‚    225    â”‚    84%       â”‚
â”‚  Tesla V100    â”‚  32 GB â”‚     64     â”‚      4     â”‚    256    â”‚    83%       â”‚
â”‚  A100          â”‚  40 GB â”‚     82     â”‚      3     â”‚    246    â”‚    85%       â”‚
â”‚  A100          â”‚  80 GB â”‚    128     â”‚      2     â”‚    256    â”‚    64%       â”‚
â”‚                                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ KEY PARAMETERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                                â”‚
â”‚  batch_size (conf/config.yaml)                                                â”‚
â”‚    Number of anchor samples per training step                                 â”‚
â”‚    â†’ Directly controls memory usage                                           â”‚
â”‚    â†’ Larger = faster training, more memory                                    â”‚
â”‚                                                                                â”‚
â”‚  accumulate_grad_batches (conf/config.yaml)                                   â”‚
â”‚    Steps to accumulate before optimizer update                                â”‚
â”‚    â†’ No memory cost, simulates larger batch                                   â”‚
â”‚    â†’ Effective batch = batch_size Ã— accumulate_grad_batches                   â”‚
â”‚                                                                                â”‚
â”‚  n_positives (conf/curriculum/XX_stage.yaml)                                  â”‚
â”‚    Number of positive samples per anchor                                      â”‚
â”‚    â†’ Increases memory linearly                                                â”‚
â”‚    â†’ Stage 01: 32, Stages 02-05: 16                                          â”‚
â”‚                                                                                â”‚
â”‚  n_negatives (conf/curriculum/XX_stage.yaml)                                  â”‚
â”‚    Number of negative samples per anchor                                      â”‚
â”‚    â†’ Increases memory linearly                                                â”‚
â”‚    â†’ Stage 01: 24, Stages 02-05: 8                                           â”‚
â”‚                                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ MEMORY BREAKDOWN (Typical 24GB Config) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                                â”‚
â”‚  Component          â”‚ Size      â”‚ Description                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Model Parameters  â”‚   200 MB  â”‚ LoRA + MoE + Projection                     â”‚
â”‚  Optimizer State   â”‚   800 MB  â”‚ AdamW (momentum + variance)                 â”‚
â”‚  Gradients         â”‚   200 MB  â”‚ Gradient tensors                            â”‚
â”‚  Activations       â”‚ 17500 MB  â”‚ Intermediate tensors (with checkpointing)   â”‚
â”‚  Batch Data        â”‚    37 MB  â”‚ Input tokens + masks                        â”‚
â”‚  Overhead          â”‚  1500 MB  â”‚ CUDA context + PyTorch                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  TOTAL             â”‚ ~20.0 GB  â”‚ For batch_size=45, n_neg=24                 â”‚
â”‚                                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ TROUBLESHOOTING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                                â”‚
â”‚  ğŸ”´ OOM (Out of Memory) Error                                                 â”‚
â”‚    1. Reduce batch_size by 25-50%                                             â”‚
â”‚    2. Increase accumulate_grad_batches proportionally                         â”‚
â”‚    3. Reduce n_negatives in stage 01                                          â”‚
â”‚    4. Clear GPU cache: python -c "import torch; torch.cuda.empty_cache()"    â”‚
â”‚                                                                                â”‚
â”‚  ğŸŸ¡ Memory Underutilized (<60%)                                               â”‚
â”‚    1. Increase batch_size by 25%                                              â”‚
â”‚    2. Re-run optimizer: --auto --apply                                        â”‚
â”‚    3. Check for other GPU processes: nvidia-smi                               â”‚
â”‚                                                                                â”‚
â”‚  ğŸŸ¢ Optimal Utilization                                                        â”‚
â”‚    â€¢ Memory usage: 80-90% of available                                        â”‚
â”‚    â€¢ Stable after first few steps                                             â”‚
â”‚    â€¢ No OOM errors                                                             â”‚
â”‚    â€¢ Smooth loss curves                                                        â”‚
â”‚                                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ OPTIMIZATION TIPS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                                â”‚
â”‚  ğŸ’¡ Maximize Throughput                                                       â”‚
â”‚    â€¢ Use 80-90% of GPU memory                                                 â”‚
â”‚    â€¢ Prefer larger batch_size over accumulation (less overhead)               â”‚
â”‚    â€¢ Enable gradient checkpointing (default: on)                              â”‚
â”‚                                                                                â”‚
â”‚  ğŸ’¡ Maximize Training Quality                                                 â”‚
â”‚    â€¢ Target effective batch size: 256-512                                     â”‚
â”‚    â€¢ More negatives in early stages (if memory allows)                        â”‚
â”‚    â€¢ Larger batches = more stable gradients                                   â”‚
â”‚                                                                                â”‚
â”‚  ğŸ’¡ Safety Margins                                                             â”‚
â”‚    â€¢ Default: 85% of available memory                                         â”‚
â”‚    â€¢ Conservative: 75% (safer, less utilization)                              â”‚
â”‚    â€¢ Aggressive: 90% (risky, max utilization)                                 â”‚
â”‚                                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ FILES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                                â”‚
â”‚  Configuration:                                                                â”‚
â”‚    conf/config.yaml                 - Main training config                    â”‚
â”‚    conf/curriculum/01_stage.yaml    - Early training (high memory)            â”‚
â”‚    conf/curriculum/02-05_stage.yaml - Later stages (lower memory)             â”‚
â”‚                                                                                â”‚
â”‚  Scripts:                                                                      â”‚
â”‚    scripts/optimize_gpu_config.py   - Main optimization tool                  â”‚
â”‚    scripts/show_current_config.py   - Display current settings                â”‚
â”‚    scripts/example_optimizer_usage.py - Usage examples                        â”‚
â”‚                                                                                â”‚
â”‚  Documentation:                                                                â”‚
â”‚    docs/gpu_optimization.md         - Comprehensive guide                     â”‚
â”‚    docs/SUMMARY_GPU_OPTIMIZATION.md - Detailed summary                        â”‚
â”‚    scripts/README.md                - Script documentation                    â”‚
â”‚                                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ WORKFLOW â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                                â”‚
â”‚  1. Check current config                                                      â”‚
â”‚     uv run python scripts/show_current_config.py                              â”‚
â”‚                                                                                â”‚
â”‚  2. Get recommendations                                                        â”‚
â”‚     uv run python scripts/optimize_gpu_config.py --auto                       â”‚
â”‚                                                                                â”‚
â”‚  3. Apply settings                                                             â”‚
â”‚     uv run python scripts/optimize_gpu_config.py --auto --apply               â”‚
â”‚                                                                                â”‚
â”‚  4. Start training                                                             â”‚
â”‚     uv run naics-embedder train --stage 01                                    â”‚
â”‚                                                                                â”‚
â”‚  5. Monitor GPU (separate terminal)                                            â”‚
â”‚     watch -n 1 nvidia-smi                                                      â”‚
â”‚                                                                                â”‚
â”‚  6. Adjust if needed                                                           â”‚
â”‚     â€¢ OOM: reduce batch_size                                                   â”‚
â”‚     â€¢ Underutilized: increase batch_size                                       â”‚
â”‚                                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  For detailed information: docs/gpu_optimization.md                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
