{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abaac491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------------------\n",
    "# Imports and settings\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "import logging\n",
    "import operator\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterator, List, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "from naics_embedder.utils.config import StreamingConfig\n",
    "from naics_embedder.utils.utilities import get_indices_codes\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(message)s',\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# Utility functions\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "def _get_config_dict(cfg: StreamingConfig) -> Dict[str, Any]:\n",
    "\n",
    "    keep = [\n",
    "        'anchor_level', 'relation_margin', 'distance_margin', \n",
    "        'positive_level', 'positive_relation', 'positive_distance', \n",
    "        'negative_level', 'negative_relation', 'negative_distance', \n",
    "        'n_positives', 'n_negatives'\n",
    "    ]\n",
    "\n",
    "    cfg_dict: Dict[str, Any] = {}\n",
    "    for k, v in cfg.model_dump().items():\n",
    "        if k in keep and v is not None:\n",
    "            cfg_dict[k] = v\n",
    "\n",
    "    return cfg_dict\n",
    "\n",
    "\n",
    "def _get_weighted_sample(\n",
    "    df: pl.DataFrame,\n",
    "    group_col: Union[str, List[str]],\n",
    "    weight_col: str,\n",
    "    n_samples: int,\n",
    "    seed: Optional[int] = None\n",
    "):\n",
    "    \n",
    "    if seed is not None:\n",
    "        rng = np.random.default_rng(seed)\n",
    "    else:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    df_len = df.height\n",
    "    \n",
    "    df = (\n",
    "        df\n",
    "        .with_columns(\n",
    "            rnd=pl.Series('rnd', rng.uniform(size=df_len))\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return (\n",
    "        df\n",
    "        .with_columns(\n",
    "            norm_wgt=pl.col(weight_col)\n",
    "                       .truediv(pl.col(weight_col).sum().over(group_col))\n",
    "        )\n",
    "        .with_columns(\n",
    "            gm_sort=pl.col('rnd').log().mul(-1)\n",
    "                      .truediv(pl.col('norm_wgt'))\n",
    "        )\n",
    "        .sort('gm_sort')\n",
    "        .group_by(group_col, maintain_order=True)\n",
    "        .head(n_samples)\n",
    "        .drop('rnd', 'norm_wgt', 'gm_sort')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a6bb489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of anchors:  404\n",
      "Number of anchors/positives:  12,797\n",
      "Number of anchors/positives/negatives:  409,504\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# Triplet batch generator\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "#def create_streaming_generator(\n",
    "#    cfg: StreamingConfig\n",
    "#) -> Iterator[Dict[str, Any]]:\n",
    "\n",
    "cfg = StreamingConfig(\n",
    "    anchor_level=[3, 4],\n",
    "    n_positives=32,\n",
    "    n_negatives=32\n",
    ")\n",
    "\n",
    "# Parameters from StreamingConfig\n",
    "descriptions_parquet = cfg.descriptions_parquet\n",
    "triplets_parquet = cfg.triplets_parquet\n",
    "anchor_level = cfg.anchor_level\n",
    "n_positives = cfg.n_positives\n",
    "n_negatives = cfg.n_negatives\n",
    "\n",
    "# Get all codes and code to index mapping\n",
    "codes = get_indices_codes(descriptions_parquet, return_type='codes')\n",
    "code_to_idx = get_indices_codes(descriptions_parquet, return_type='code_to_idx')\n",
    "\n",
    "# Organize codes by level\n",
    "level_dict = defaultdict(list)\n",
    "for code in codes:\n",
    "    level = len(code) # type: ignore\n",
    "    level_dict[level].append(code)\n",
    "\n",
    "# Get list of dataset files\n",
    "if anchor_level is not None:\n",
    "    dataset_files = []   \n",
    "    for level in anchor_level:\n",
    "        for code in level_dict[level]:\n",
    "            idx = code_to_idx[code]\n",
    "            for pq_path in Path(f'{triplets_parquet}/anchor={idx}/').glob('*.parquet'):\n",
    "                dataset_files.append(pq_path.as_posix())\n",
    "\n",
    "else:\n",
    "    dataset_files = []\n",
    "    for pq_path in Path(f'{triplets_parquet}/').glob('**/*.parquet'):\n",
    "        dataset_files.append(pq_path.as_posix())\n",
    "\n",
    "cfg_dict = _get_config_dict(cfg)\n",
    "\n",
    "# Build filters from cfg_dict\n",
    "exprs = []\n",
    "for k, v in cfg_dict.items():\n",
    "\n",
    "    if isinstance(v, list):\n",
    "        exprs.append(\n",
    "            pl.col(k).is_in(v)\n",
    "        )       \n",
    "\n",
    "    if isinstance(v, bool):\n",
    "        exprs.append(\n",
    "            pl.col(k).eq(v)\n",
    "        )\n",
    "\n",
    "if not exprs:\n",
    "    exprs = [pl.col('anchor_idx').ge(0)]\n",
    "\n",
    "filters = reduce(operator.and_, exprs)\n",
    "\n",
    "# Build (anchors, positives, negatives, fallbacks) dataframe \n",
    "df_0 = (\n",
    "    pl\n",
    "    .scan_parquet(\n",
    "        dataset_files\n",
    "    )\n",
    "    .filter(\n",
    "        filters\n",
    "    )\n",
    ")\n",
    "\n",
    "# Build final dataframe with sampled positives\n",
    "df_1 = (\n",
    "    df_0\n",
    "    .with_columns(\n",
    "        relation_margin=pl.when(pl.col('excluded'))\n",
    "                        .then(pl.col('relation_margin').add(1))\n",
    "                        .otherwise(pl.col('relation_margin')),\n",
    "        distance_margin=pl.when(pl.col('excluded'))\n",
    "                        .then(pl.col('distance_margin').add(1))\n",
    "                        .otherwise(pl.col('distance_margin'))\n",
    "    )\n",
    "    .with_columns(\n",
    "        sample_wgt=pl.mean_horizontal('relation_margin', 'distance_margin')\n",
    "                        .pow(-1)\n",
    "    )\n",
    "    .select(\n",
    "        anchors=pl.struct(\n",
    "            pl.col('anchor_idx'),\n",
    "            pl.col('anchor_code')\n",
    "        ),\n",
    "        positives=pl.struct(\n",
    "            pl.col('positive_idx'),\n",
    "            pl.col('positive_code')\n",
    "        ),\n",
    "        negatives=pl.struct(\n",
    "            pl.struct(\n",
    "                pl.col('negative_idx'),\n",
    "                pl.col('negative_code'),\n",
    "                pl.col('relation_margin'),\n",
    "                pl.col('distance_margin')\n",
    "            ).alias('negatives'),\n",
    "            pl.col('sample_wgt')\n",
    "        ),\n",
    "    )\n",
    "    .group_by('anchors', 'positives')\n",
    "    .agg(\n",
    "        negatives=pl.col('negatives')\n",
    "    )\n",
    "    .select(\n",
    "        anchors=pl.col('anchors'), \n",
    "        positives_negatives=pl.struct(\n",
    "            pl.col('positives'),\n",
    "            pl.col('negatives')\n",
    "        )\n",
    "    )\n",
    "    .group_by('anchors')\n",
    "    .agg(\n",
    "        positives_negatives_len=pl.col('positives_negatives').len(),\n",
    "        positives_negatives=pl.col('positives_negatives')\n",
    "    )\n",
    "    .with_columns(\n",
    "        positives_negatives_len=pl.min_horizontal(\n",
    "            pl.col('positives_negatives_len'),\n",
    "            pl.lit(n_positives)\n",
    "        )\n",
    "    )\n",
    "    .with_columns(\n",
    "        positives_negatives=pl.col('positives_negatives')\n",
    "                    .list.sample(\n",
    "                        pl.col('positives_negatives_len'), \n",
    "                        shuffle=True, \n",
    "                        seed=cfg.seed\n",
    "                    )\n",
    "    )\n",
    "    .drop('positives_negatives_len')\n",
    "    .explode('positives_negatives')\n",
    "    .unnest('positives_negatives')\n",
    "    .explode('negatives')\n",
    "    .unnest('negatives')\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "# Build final dataframe with sampled positives and negatives\n",
    "df = (\n",
    "    _get_weighted_sample(\n",
    "        df_1,\n",
    "        ['anchors', 'positives'],\n",
    "        'sample_wgt',\n",
    "        n_negatives,\n",
    "        seed=cfg.seed\n",
    "    )\n",
    "    .group_by('anchors', 'positives')\n",
    "    .agg(\n",
    "        negatives=pl.col('negatives'),\n",
    "        negatives_len=pl.col('negatives').len()\n",
    "    )\n",
    "    .select(\n",
    "        anchors=pl.col('anchors'),\n",
    "        positives=pl.col('positives'),\n",
    "        negatives=pl.col('negatives'),\n",
    "        negatives_len=pl.col('negatives_len')\n",
    "    )\n",
    ")\n",
    "\n",
    "logger.info(f'Number of anchors: {df.unnest(\"anchors\").select(\"anchor_idx\").unique().height: ,}')\n",
    "logger.info(f'Number of anchors/positives: {df.height: ,}')\n",
    "logger.info(f'Number of anchors/positives/negatives: {df.explode(\"negatives\").height: ,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3280aafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.unnest(\"anchors\").get_column(\"anchor_idx\").unique().len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "903a96af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anchor_idx': 199, 'anchor_code': '2361', 'positive_idx': 205, 'positive_code': '2362', 'negatives': [{'negative_idx': 231, 'negative_code': '23812', 'relation_margin': 8, 'distance_margin': 7}, {'negative_idx': 203, 'negative_code': '236117', 'relation_margin': 1, 'distance_margin': 1}, {'negative_idx': 221, 'negative_code': '2373', 'relation_margin': 5, 'distance_margin': 6}, {'negative_idx': 201, 'negative_code': '236115', 'relation_margin': 1, 'distance_margin': 1}, {'negative_idx': 431, 'negative_code': '321991', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 1374, 'negative_code': '513199', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 268, 'negative_code': '23899', 'relation_margin': 8, 'distance_margin': 7}, {'negative_idx': 260, 'negative_code': '238340', 'relation_margin': 10, 'distance_margin': 8}, {'negative_idx': 1048, 'negative_code': '424920', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 235, 'negative_code': '23814', 'relation_margin': 8, 'distance_margin': 7}, {'negative_idx': 226, 'negative_code': '237990', 'relation_margin': 10, 'distance_margin': 8}, {'negative_idx': 208, 'negative_code': '23622', 'relation_margin': 3, 'distance_margin': 4}, {'negative_idx': 202, 'negative_code': '236116', 'relation_margin': 1, 'distance_margin': 1}, {'negative_idx': 229, 'negative_code': '23811', 'relation_margin': 8, 'distance_margin': 7}, {'negative_idx': 239, 'negative_code': '23816', 'relation_margin': 8, 'distance_margin': 7}, {'negative_idx': 459, 'negative_code': '323117', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 262, 'negative_code': '238350', 'relation_margin': 10, 'distance_margin': 8}, {'negative_idx': 254, 'negative_code': '238310', 'relation_margin': 10, 'distance_margin': 8}, {'negative_idx': 265, 'negative_code': '2389', 'relation_margin': 5, 'distance_margin': 6}, {'negative_idx': 218, 'negative_code': '2372', 'relation_margin': 5, 'distance_margin': 6}, {'negative_idx': 261, 'negative_code': '23835', 'relation_margin': 8, 'distance_margin': 7}, {'negative_idx': 1643, 'negative_code': '551112', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 230, 'negative_code': '238110', 'relation_margin': 10, 'distance_margin': 8}, {'negative_idx': 223, 'negative_code': '237310', 'relation_margin': 10, 'distance_margin': 8}, {'negative_idx': 249, 'negative_code': '238220', 'relation_margin': 10, 'distance_margin': 8}, {'negative_idx': 219, 'negative_code': '23721', 'relation_margin': 8, 'distance_margin': 7}, {'negative_idx': 224, 'negative_code': '2379', 'relation_margin': 5, 'distance_margin': 6}, {'negative_idx': 244, 'negative_code': '238190', 'relation_margin': 10, 'distance_margin': 8}, {'negative_idx': 222, 'negative_code': '23731', 'relation_margin': 8, 'distance_margin': 7}, {'negative_idx': 206, 'negative_code': '23621', 'relation_margin': 3, 'distance_margin': 4}, {'negative_idx': 240, 'negative_code': '238160', 'relation_margin': 10, 'distance_margin': 8}, {'negative_idx': 220, 'negative_code': '237210', 'relation_margin': 10, 'distance_margin': 8}]}\n",
      "{'anchor_idx': 591, 'anchor_code': '331', 'positive_idx': 523, 'positive_code': '32599', 'negatives': [{'negative_idx': 389, 'negative_code': '314999', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 342, 'negative_code': '31199', 'relation_margin': 1, 'distance_margin': 1}, {'negative_idx': 488, 'negative_code': '325211', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 398, 'negative_code': '315250', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 582, 'negative_code': '327420', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 890, 'negative_code': '339940', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 720, 'negative_code': '333618', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 530, 'negative_code': '326111', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 767, 'negative_code': '334513', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 804, 'negative_code': '335999', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 283, 'negative_code': '311224', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 761, 'negative_code': '334419', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 733, 'negative_code': '333993', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 765, 'negative_code': '334511', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 642, 'negative_code': '332321', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 888, 'negative_code': '339930', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 325, 'negative_code': '311813', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 433, 'negative_code': '321999', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 651, 'negative_code': '332431', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 532, 'negative_code': '326113', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 680, 'negative_code': '332993', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 789, 'negative_code': '335311', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 502, 'negative_code': '325411', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 871, 'negative_code': '337910', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 758, 'negative_code': '334416', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 848, 'negative_code': '336612', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 673, 'negative_code': '332911', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 814, 'negative_code': '336212', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 284, 'negative_code': '311225', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 535, 'negative_code': '326122', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 534, 'negative_code': '326121', 'relation_margin': 1, 'distance_margin': 3}, {'negative_idx': 662, 'negative_code': '332710', 'relation_margin': 1, 'distance_margin': 3}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Iterate by rows and yield dictionaries\n",
    "for row in list(df.iter_rows(named=True))[:2]:\n",
    "    \n",
    "    grouped = {}\n",
    "    key = (row['anchors']['anchor_idx'], row['positives']['positive_idx'])\n",
    "\n",
    "    negatives = []\n",
    "    for negative in row['negatives']:\n",
    "        negative_idx = negative['negative_idx']\n",
    "        negative_code = negative['negative_code']\n",
    "        relation_margin = negative['relation_margin']\n",
    "        distance_margin = negative['distance_margin']\n",
    "\n",
    "        negatives.append({\n",
    "            'negative_idx': negative_idx,\n",
    "            'negative_code': negative_code,\n",
    "            'relation_margin': relation_margin,\n",
    "            'distance_margin': distance_margin\n",
    "        })\n",
    "\n",
    "    if key not in grouped:\n",
    "        grouped[key] = {\n",
    "            'anchor_idx': row['anchors']['anchor_idx'],\n",
    "            'anchor_code': row['anchors']['anchor_code'],\n",
    "            'positive_idx': row['positives']['positive_idx'],\n",
    "            'positive_code': row['positives']['positive_code'],\n",
    "            'negatives': negatives\n",
    "        }\n",
    "\n",
    "    print(grouped[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b97dd711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anchor_idx': 462, 'anchor_code': '324', 'positive_idx': 565, 'positive_code': '327212', 'negatives': [{'negative_idx': 566, 'negative_code': '327213', 'relation_margin': 1, 'distance_margin': 1}, {'negative_idx': 797, 'negative_code': '335921', 'relation_margin': 1, 'distance_margin': 1}, {'negative_idx': 1684, 'negative_code': '561591', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 589, 'negative_code': '327993', 'relation_margin': 1, 'distance_margin': 1}, {'negative_idx': 1518, 'negative_code': '532120', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 2024, 'negative_code': '813211', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 567, 'negative_code': '327215', 'relation_margin': 1, 'distance_margin': 1}, {'negative_idx': 1774, 'negative_code': '621111', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 1823, 'negative_code': '622310', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 1430, 'negative_code': '522291', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 1939, 'negative_code': '721310', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 1918, 'negative_code': '713940', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 2078, 'negative_code': '922160', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 1956, 'negative_code': '722515', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 1209, 'negative_code': '481212', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 1803, 'negative_code': '621511', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 1969, 'negative_code': '811198', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 1160, 'negative_code': '458210', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 1070, 'negative_code': '441210', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 1676, 'negative_code': '561492', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 1072, 'negative_code': '441222', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 69, 'negative_code': '112310', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 168, 'negative_code': '213112', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 1885, 'negative_code': '711410', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 1789, 'negative_code': '621391', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 1365, 'negative_code': '513110', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 186, 'negative_code': '221122', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 1652, 'negative_code': '561210', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 1628, 'negative_code': '541910', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 2025, 'negative_code': '813212', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 53, 'negative_code': '111992', 'relation_margin': 99, 'distance_margin': 99}, {'negative_idx': 155, 'negative_code': '212312', 'relation_margin': 99, 'distance_margin': 99}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for anchor in list(df_iter)[2:3]:\n",
    "    \n",
    "    anchor_iter = (\n",
    "        df_dict[anchor]\n",
    "        .iter_rows(named=True)\n",
    "    )\n",
    "\n",
    "    for row in (anchor_iter):\n",
    "        grouped = {}\n",
    "        key = (row['anchors']['anchor_idx'], row['positives']['positive_idx'])\n",
    "\n",
    "        negatives = []\n",
    "        for negative in row['negatives']:\n",
    "            negative_idx = negative['negative_idx']\n",
    "            negative_code = negative['negative_code']\n",
    "            relation_margin = negative['relation_margin']\n",
    "            distance_margin = negative['distance_margin']\n",
    "\n",
    "            negatives.append({\n",
    "                'negative_idx': negative_idx,\n",
    "                'negative_code': negative_code,\n",
    "                'relation_margin': relation_margin,\n",
    "                'distance_margin': distance_margin\n",
    "            })\n",
    "\n",
    "        if key not in grouped:\n",
    "            grouped[key] = {\n",
    "                'anchor_idx': row['anchors']['anchor_idx'],\n",
    "                'anchor_code': row['anchors']['anchor_code'],\n",
    "                'positive_idx': row['positives']['positive_idx'],\n",
    "                'positive_code': row['positives']['positive_code'],\n",
    "                'negatives': negatives\n",
    "            }\n",
    "\n",
    "        print(grouped[key])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b5161b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    for triplets in triplets_iterator:\n",
    "        \n",
    "        anchor_idx = triplets['anchor_idx']\n",
    "        anchor_code = triplets['anchor_code']\n",
    "        anchor_embedding = {k: v for k, v in token_cache[anchor_idx].items() if k != 'code'}\n",
    "\n",
    "        positive_idx = triplets['positive_idx']\n",
    "        positive_code = triplets['positive_code']\n",
    "        positive_embedding = {k: v for k, v in token_cache[positive_idx].items() if k != 'code'}\n",
    "        \n",
    "        negatives = []\n",
    "        for negative in triplets['negatives']:\n",
    "\n",
    "            negative_idx = negative['negative_idx']\n",
    "            negative_code = negative['negative_code']\n",
    "            negative_embedding = {k: v for k, v in token_cache[negative_idx].items() if k != 'code'}\n",
    "            \n",
    "            relation_margin = negative['relation_margin']\n",
    "            distance_margin = negative['distance_margin']\n",
    "\n",
    "            negatives.append({\n",
    "                'negative_idx': negative_idx,\n",
    "                'negative_code': negative_code,\n",
    "                'negative_embedding': negative_embedding,\n",
    "                'relation_margin': relation_margin,\n",
    "                'distance_margin': distance_margin\n",
    "            })\n",
    "\n",
    "        yield {\n",
    "            'anchor_idx': anchor_idx,\n",
    "            'anchor_code': anchor_code,\n",
    "            'anchor_embedding': anchor_embedding,\n",
    "            'positive_idx': positive_idx,\n",
    "            'positive_code': positive_code,\n",
    "            'positive_embedding': positive_embedding,\n",
    "            'negatives': negatives\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492e91c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naics-embedder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
