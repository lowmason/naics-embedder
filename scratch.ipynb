{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6bc386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------------------\n",
    "# Imports and settings\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "import logging\n",
    "from dataclasses import replace\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "\n",
    "from naics_gemini.data_loader.streaming_dataset import (\n",
    "    CurriculumConfig,\n",
    "    create_streaming_dataset,\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# Collate function for DataLoader\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "def collate_fn(batch: List[Dict]) -> Dict:\n",
    "\n",
    "    '''\n",
    "    Collate function for batching training examples.\n",
    "    \n",
    "    Args:\n",
    "        batch: List of training examples from streaming dataset\n",
    "        \n",
    "    Returns:\n",
    "        Batched tensors ready for model input\n",
    "    '''\n",
    "    \n",
    "    channels = ['title', 'description', 'excluded', 'examples']\n",
    "    \n",
    "    # Initialize batch dictionaries\n",
    "    anchor_batch = {channel: {} for channel in channels}\n",
    "    positive_batch = {channel: {} for channel in channels}\n",
    "    negatives_batch = {channel: {} for channel in channels}\n",
    "    \n",
    "    # Collect codes and indices for evaluation tracking\n",
    "    anchor_codes = []\n",
    "    positive_codes = []\n",
    "    negative_codes = []\n",
    "    \n",
    "    # Process each channel\n",
    "    for channel in channels:\n",
    "        anchor_ids = []\n",
    "        anchor_masks = []\n",
    "        positive_ids = []\n",
    "        positive_masks = []\n",
    "        \n",
    "        # Collect anchor and positive for this channel\n",
    "        for item in batch:\n",
    "            anchor_ids.append(item['anchor_embedding'][channel]['input_ids'])\n",
    "            anchor_masks.append(item['anchor_embedding'][channel]['attention_mask'])\n",
    "            positive_ids.append(item['positive_embedding'][channel]['input_ids'])\n",
    "            positive_masks.append(item['positive_embedding'][channel]['attention_mask'])\n",
    "        \n",
    "        # Stack anchor\n",
    "        anchor_batch[channel]['input_ids'] = torch.stack(anchor_ids)\n",
    "        anchor_batch[channel]['attention_mask'] = torch.stack(anchor_masks)\n",
    "        \n",
    "        # Stack positive\n",
    "        positive_batch[channel]['input_ids'] = torch.stack(positive_ids)\n",
    "        positive_batch[channel]['attention_mask'] = torch.stack(positive_masks)\n",
    "        \n",
    "        # Collect all negatives for this channel\n",
    "        all_neg_ids = []\n",
    "        all_neg_masks = []\n",
    "        for item in batch:\n",
    "            for neg_dict in item['negatives']:\n",
    "                all_neg_ids.append(neg_dict['negative_embedding'][channel]['input_ids'])\n",
    "                all_neg_masks.append(neg_dict['negative_embedding'][channel]['attention_mask'])\n",
    "        \n",
    "        # Stack negatives\n",
    "        negatives_batch[channel]['input_ids'] = torch.stack(all_neg_ids)\n",
    "        negatives_batch[channel]['attention_mask'] = torch.stack(all_neg_masks)\n",
    "    \n",
    "    # Extract codes from batch items\n",
    "    for item in batch:\n",
    "        anchor_codes.append(item['anchor_code'])\n",
    "        positive_codes.append(item['positive_code'])\n",
    "        for neg_dict in item['negatives']:\n",
    "            negative_codes.append(neg_dict['negative_code'])\n",
    "    \n",
    "    return {\n",
    "        'anchor': anchor_batch,\n",
    "        'positive': positive_batch,\n",
    "        'negatives': negatives_batch,\n",
    "        'batch_size': len(batch),\n",
    "        'k_negatives': len(batch[0]['negatives']),\n",
    "        'anchor_code': anchor_codes,\n",
    "        'positive_code': positive_codes,\n",
    "        'negative_codes': negative_codes\n",
    "    }\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# Wrapper to make generator function work with DataLoader\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "class GeneratorDataset(IterableDataset):\n",
    "\n",
    "    '''Wrapper to make a generator function work with PyTorch DataLoader.'''\n",
    "    \n",
    "    def __init__(self, generator_fn, *args, **kwargs):\n",
    "        self.generator_fn = generator_fn\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.generator_fn(*self.args, **self.kwargs)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# Main DataModule for PyTorch Lightning (optional but recommended)\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "class NAICSDataModule:\n",
    "\n",
    "    '''\n",
    "    Data module for NAICS contrastive learning.\n",
    "    \n",
    "    This class encapsulates all data loading logic including:\n",
    "    - Tokenization caching\n",
    "    - Curriculum-based filtering\n",
    "    - Streaming dataset creation\n",
    "    - DataLoader configuration\n",
    "    '''\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        curriculum_config: CurriculumConfig,\n",
    "        batch_size: int = 32,\n",
    "        num_workers: int = 1,\n",
    "        seed: int = 42\n",
    "    ):\n",
    "        '''\n",
    "        Initialize NAICS DataModule.\n",
    "        \n",
    "        Args:\n",
    "            curriculum_config: instance of CurriculumConfig or None\n",
    "            batch_size: Batch size for training\n",
    "            num_workers: Number of dataloader workers\n",
    "            seed: Random seed for training dataset\n",
    "        '''\n",
    "\n",
    "        self.curriculum = curriculum_config\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.seed = seed\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "    \n",
    "    \n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "\n",
    "        '''\n",
    "        Setup datasets.\n",
    "        \n",
    "        Args:\n",
    "            stage: 'fit', 'validate', 'test', or 'predict'\n",
    "        '''\n",
    "        \n",
    "        logger.info('Setting up NAICS DataModule...')\n",
    "        \n",
    "        if stage == 'fit' or stage is None:\n",
    "\n",
    "            # Create training dataset\n",
    "            logger.info('Creating training dataset...')\n",
    "            self.train_dataset = GeneratorDataset(\n",
    "                create_streaming_dataset,\n",
    "                self.curriculum\n",
    "            )\n",
    "            \n",
    "            # Create validation curriculum with different seed\n",
    "            val_curriculum = replace(\n",
    "                self.curriculum,\n",
    "                seed=self.seed + 1\n",
    "            )\n",
    "            \n",
    "            logger.info('Creating validation dataset...')\n",
    "            self.val_dataset = GeneratorDataset(\n",
    "                create_streaming_dataset,\n",
    "                val_curriculum\n",
    "            )\n",
    "            \n",
    "            logger.info('DataModule setup complete!')\n",
    "    \n",
    "    \n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "\n",
    "        '''Create training dataloader.'''\n",
    "        \n",
    "        if self.train_dataset is None:\n",
    "            raise RuntimeError('Training dataset not initialized. Call setup() first.')\n",
    "        \n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn=collate_fn,\n",
    "            persistent_workers=True if self.num_workers > 0 else False\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        \n",
    "        '''Create validation dataloader.'''\n",
    "        \n",
    "        if self.val_dataset is None:\n",
    "            raise RuntimeError('Validation dataset not initialized. Call setup() first.')\n",
    "        \n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn=collate_fn,\n",
    "            persistent_workers=True if self.num_workers > 0 else False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27808918",
   "metadata": {},
   "outputs": [],
   "source": [
    "curriculum = replace(\n",
    "    CurriculumConfig(),\n",
    "    anchor_level=[2, 3],\n",
    "    positive_relation=[1, 3],\n",
    "    n_positives=100,\n",
    "    n_negatives=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f716cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datamodule = NAICSDataModule(\n",
    "    curriculum_config=curriculum,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dde56994",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.setup(stage='fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "217ad96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = datamodule.train_dataloader()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naics-gemini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
